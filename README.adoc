= SambaNova tutorials

This repository contains SambaNova tutorials that help you to learn more about the SambaNova platform. Each tutorial includes instructions for preparing the dataset, the code to run the model, and pointers to code discussions in our public documentation.

Start with the "Hello, World" tutorial, which uses a very simple model and the MNIST dataset. You follow some basic steps to run this ML models on the SambaNova platform.

Use the LeNet tutorial to experience a full ML workflow:

. Compile the model for SambaNova processors (RDU)
. Train the model using a publicly available dataset
. Save intermediate checkpoints and continue training from a checkpoint
. Run inference using one of the checkpoints and generate a predictions file
. Visualize predictions using Jupyter

Go through the `generative_nlp` tutorial to work with a Hugging Face model in the SambaNova environment. 

. Download a GPT-2 model (we've chosen a simple model to speed up compilation and fine tuning).
. Download and prepare a dataset. 
. Compile the model. 
. Fine tune the compiled model using the labeled dataset. 
. Perform inference with the unlabeled dataset to verify that training worked. 


== How to use SambaNova tutorials

. Clone this repository
+
[source,console]
----
$ git clone https://github.com/sambanova/tutorials.git
----

. Enter one of the directories, e.g. `hello_world`:
+
[source,console]
----
$ cd tutorials
# Start with the 'Hello world'
$ cd hello_world
# Or choose the intermediate tutorial that uses LeNet
$ cd lenet
----

. Follow the instructions in the README file.

== Feedback

Please provide your feedback at docs@sambanova.ai.


